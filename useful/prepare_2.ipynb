{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b380eb3b-8535-4a05-b480-87c737df7bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.plotting as pd_plt\n",
    "import matplotlib.colors as plt_colors\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "import plotly.subplots \n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b96526-2e86-454d-be27-d840d6b2af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, \\\n",
    "                                    ShuffleSplit, KFold\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, \\\n",
    "                                  RobustScaler, PolynomialFeatures, \\\n",
    "                                  OrdinalEncoder, LabelEncoder, \\\n",
    "                                  OneHotEncoder, TargetEncoder, \\\n",
    "                                  QuantileTransformer, PowerTransformer, \\\n",
    "                                  KBinsDiscretizer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression, RANSACRegressor, \\\n",
    "                                 Ridge, Lasso, LinearRegression\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, \\\n",
    "                            f1_score, ConfusionMatrixDisplay, \\\n",
    "                            confusion_matrix, roc_auc_score, \\\n",
    "                            RocCurveDisplay, PrecisionRecallDisplay, \\\n",
    "                            roc_curve, precision_recall_curve, \\\n",
    "                            PrecisionRecallDisplay, make_scorer, \\\n",
    "                            mean_squared_error, auc\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector,\\\n",
    "                            make_column_transformer, TransformedTargetRegressor\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, \\\n",
    "                             VotingRegressor, StackingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d947e-4e2e-45d3-957c-a3b89e2bab1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Ниже построение фореста и подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a802be51-450c-4af4-8759-5de40d3b1b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data1.data, data1.target, random_state=13)\n",
    "forest = RandomForestClassifier(n_estimators=1000, max_features=10, random_state=13,\n",
    "                               oob_score=True) \n",
    "forest.fit(X_train, y_train)\n",
    "print('Правильность на обучающем наборе: {:.3f}'.format(forest.score(X_train, y_train)))\n",
    "print('Правильность на OOB: {:.3f}'.format(forest.oob_score_))\n",
    "print('Правильность на тестовом наборе: {:.3f}'.format(forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b3fa0-6d2c-40de-8f2c-f2294d1495d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор критерия\n",
    "sc_train1 = []\n",
    "sc_oob1 = []\n",
    "sc_train2 = []\n",
    "sc_oob2 = []\n",
    "n_estimators = [200, 500, 1000, 5000]\n",
    "for n in n_estimators:\n",
    "    rf = RandomForestClassifier(n_estimators=n, random_state=13, n_jobs=-1, oob_score=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    sc_train_n = rf.score(X_train, y_train)\n",
    "    sc_oob_n = rf.oob_score_\n",
    "    sc_train1.append(sc_train_n)\n",
    "    sc_oob1.append(sc_oob_n)\n",
    "\n",
    "for n in n_estimators:\n",
    "    rf = RandomForestClassifier(n_estimators=n, random_state=13, n_jobs=-1, criterion='entropy', oob_score=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    sc_train_n = rf.score(X_train, y_train)\n",
    "    sc_oob_n = rf.oob_score_\n",
    "    sc_train2.append(sc_train_n)\n",
    "    sc_oob2.append(sc_oob_n)    \n",
    "    \n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax1.plot(n_estimators,sc_train1)\n",
    "ax1.plot(n_estimators,sc_oob1)\n",
    "#ax1.set_ylim(0.9, 1.01)\n",
    "ax2.plot(n_estimators,sc_train2)\n",
    "ax2.plot(n_estimators,sc_oob2)\n",
    "#ax2.set_ylim(0.9, 1.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e9fcd-23d6-42c5-b423-abc30a528350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Важность фичей, не особо актуально, когда есть вектора шепли\n",
    "def plot_feature_importances_cancer(model):\n",
    "    n_features = data1.shape[1]\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), cancer.feature_names) \n",
    "    plt.xlabel(\"Важность признака\")\n",
    "    plt.ylabel(\"Признак\")\n",
    "plt.figure(figsize = (15, 10))\n",
    "plot_feature_importances_cancer(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56503ee6-915e-4b1f-b6e4-4186e087d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор числа фичей\n",
    "min_features = 1\n",
    "max_features = data1.shape[1]\n",
    "\n",
    "ensemble_clfs = [\n",
    "    (\n",
    "        \"RandomForestClassifier, gini\",\n",
    "        RandomForestClassifier(\n",
    "            criterion='gini',\n",
    "             min_samples_leaf = 5,\n",
    "            n_jobs = -1,\n",
    "            oob_score=True,\n",
    "            random_state=13,\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"RandomForestClassifier, entropy\",\n",
    "        RandomForestClassifier(\n",
    "            criterion='entropy',\n",
    "             min_samples_leaf = 5,\n",
    "            n_jobs = -1,\n",
    "            oob_score=True,\n",
    "            random_state=13,\n",
    "        ),\n",
    "    )\n",
    "]\n",
    "\n",
    "# Сопоставляем имя классификатора со списком пар (<n_estimators>, <коэффициент ошибок>).\n",
    "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
    "\n",
    "for label, clf in ensemble_clfs:\n",
    "    for i in range(min_features, max_features + 1):\n",
    "        clf.set_params(n_estimators = 500, max_features = i)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Запишем ошибку OOB для каждой настройки `n_estimators=i`.\n",
    "        oob_error = 1 - clf.oob_score_\n",
    "        error_rate[label].append((i, oob_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867532f5-e078-4e45-8210-515a850f6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, clf_err in error_rate.items():\n",
    "    xs, ys = zip(*clf_err)\n",
    "    plt.plot(xs, ys, label=label)\n",
    "\n",
    "plt.xlim(min_features, max_features)\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeaf67b-4e4e-40ee-950e-5f05b0c00b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values_max_features = []\n",
    "for i in range(1, 15):\n",
    "    RF = RandomForest(n_estimators=500,n_jobs=-1, max_features=i, min_samples_leaf=5)\n",
    "    RF.fit(X_train, y_train)\n",
    "    y_values_max_features.append(RF.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa04a5-f25c-4af4-93ff-7814eb885abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График для подбора\n",
    "plt.figure(figsize=(8, 5))  \n",
    "plt.plot(range(1, 10), y_values_max_features)  \n",
    "plt.xlabel(\"max_features\")          \n",
    "plt.ylabel(\"score\")          \n",
    "plt.legend() \n",
    "plt.axvline(color='red', linestyle='--')\n",
    "#plt.grid(True)                \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfaa6d6-b3d6-4ec6-a3e2-459f8e777378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор оптимальной глубины деревьев в лесе\n",
    "y_values_max_depth = []\n",
    "for n in range(1, 10):\n",
    "    RF = RandomForest(n_estimators=500,n_jobs=-1, max_features='log2', min_samples_leaf=5, max_depth=n)\n",
    "    RF.fit(X_train, y_train)\n",
    "    y_values_max_depth.append(RF.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e0dc4-de36-4051-a346-259bcd8895c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График для подбора\n",
    "plt.figure(figsize=(8, 5))  \n",
    "plt.plot(range(1, 10), y_values_max_depth)  \n",
    "plt.xlabel(\"max_depth\")          \n",
    "plt.ylabel(\"score\")          \n",
    "plt.legend() \n",
    "plt.axvline(color='red', linestyle='--')\n",
    "#plt.grid(True)                \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89897c76-de29-4c04-abbc-c0a7d1abf863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор минимального числа семплов в листе\n",
    "y_values_min_samples = []\n",
    "for n in range(1, 31):\n",
    "    RF = RandomForestClassifier(n_estimators=500,n_jobs=-1, max_features='log2', min_samples_leaf=n)\n",
    "    RF.fit(X_train, y_train)\n",
    "    y_values_min_samples.append(RF.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61f3a38-9d04-422e-8194-d33dec0b9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График для подбора\n",
    "plt.figure(figsize=(8, 5))  \n",
    "plt.plot(range(1, 31), y_values_min_samples)  \n",
    "plt.xlabel(\"min_samples_leaf\")          \n",
    "plt.ylabel(\"score\")          \n",
    "plt.legend() \n",
    "plt.axvline(x=5, color='red', linestyle='--')               \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63fa6c-159e-4ee9-9292-007dc34940c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d79574-4db2-42da-9ced-51b5435979bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(random_state=13, max_depth=5, n_estimators=500, learning_rate=0.05, max_features='sqrt', subsample=0.5)\n",
    "gbrt.fit(X_train, y_train)\n",
    "print('Правильность на обучающем наборе: {:.3f}'.format(gbrt.score(X_train, y_train)))\n",
    "print('Правильность на тестовом наборе: {:.3f}'.format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638acbab-8dfb-4364-8d8f-6382a7c2eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate u subsample\n",
    "y_values_GB_0_5 = []\n",
    "y_values_GB_0_75 = []\n",
    "y_values_GB_1 = []\n",
    "\n",
    "for lr in [0.01, 0.05, 0.1, 0.5]:\n",
    "    GB_0_5 = GradientBoostingRegressor(random_state=13, n_estimators=500, learning_rate=lr, subsample=0.5)\n",
    "    GB_0_5.fit(X_train, y_train)\n",
    "    y_values_GB_0_5.append(GB_0_5.score(X_test, y_test))\n",
    "    GB_0_75 = GradientBoostingRegressor(random_state=13, n_estimators=500, learning_rate=lr, subsample=0.75)\n",
    "    GB_0_75.fit(X_train, y_train)\n",
    "    y_values_GB_0_75.append(GB_0_75.score(X_test, y_test))\n",
    "    GB_1 = GradientBoostingRegressor(random_state=13, n_estimators=500, learning_rate=lr, subsample=1.0\n",
    "    GB_1.fit(X_train, y_train)\n",
    "    y_values_GB_1.append(GB_1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff687704-4116-4fb9-b559-4f3d5779afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График для подбора\n",
    "x = [0.01, 0.05, 0.1, 0.5]\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y_values_GB_0_5, label ='subsample=0.5')\n",
    "plt.plot(x, y_values_GB_0_75, label ='subsample=0.75')\n",
    "plt.plot(x, y_values_GB_1, label ='subsample=1')\n",
    "plt.xlabel(\"learning_rate_GB\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.legend()\n",
    "plt.axvline(color='red', linestyle='')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c85e9c-325b-44d9-8dce-62cedba37b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Максимальное число фичей\n",
    "y_values_max_features_GB = []\n",
    "for n in range(1, 20, 2):\n",
    "    GB = GradientBoostingRegressor(random_state=13, n_estimators=500, learning_rate=0.05, max_features=n, subsample=0.5)\n",
    "    GB.fit(X_train, y_train)\n",
    "    y_values_max_features_GB.append(GB.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf2f995-816c-4d85-97af-dad37dd5636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График для подбора\n",
    "plt.figure(figsize=(8, 5))  \n",
    "plt.plot(range(1, 20, 2), y_values_max_features_GB)  \n",
    "plt.xlabel(\"max_features_GB\")          \n",
    "plt.ylabel(\"score\")          \n",
    "plt.legend() \n",
    "plt.axvline(color='red', linestyle='--')\n",
    "#plt.grid(True)                \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4622f-bef8-4d87-9444-1c74b98845b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор оптимальной глубины деревьев в лесе\n",
    "y_values_max_depth_GB = []\n",
    "for n in range(1, 6):\n",
    "    GB = GradientBoostingRegressor(random_state=13, max_depth=n, n_estimators=500, learning_rate=0.05, max_features='sqrt', subsample=0.5)\n",
    "    GB.fit(X_train, y_train)\n",
    "    y_values_max_depth_GB.append(GB.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855a847-69c0-4981-a6ea-d5b7b0144c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График для подбора\n",
    "plt.figure(figsize=(8, 5))  \n",
    "plt.plot(range(1, 6), y_values_max_depth_GB)  \n",
    "plt.xlabel(\"max_depth_GB\")          \n",
    "plt.ylabel(\"score\")          \n",
    "plt.legend() \n",
    "plt.axvline(color='red', linestyle='--')\n",
    "#plt.grid(True)                \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24cda3c-e760-46fa-87f3-b2186b276610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор минимального числа семплов в листе\n",
    "y_values_min_samples_GB = []\n",
    "for n in range(1, 100, 10):\n",
    "    GB = GradientBoostingRegressor(random_state=13, max_depth=5, n_estimators=500, learning_rate=0.05, max_features='sqrt', subsample=0.5, min_samples_leaf=n)\n",
    "    GB.fit(X_train, y_train)\n",
    "    y_values_min_samples_GB.append(GB.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cbd207-cb93-4124-8835-13e0b923f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График для подбора\n",
    "plt.figure(figsize=(8, 5))  \n",
    "plt.plot(range(1, 100, 10), y_values_min_samples_GB)  \n",
    "plt.xlabel(\"min_samples_leaf_GB\")          \n",
    "plt.ylabel(\"score\")          \n",
    "plt.legend() \n",
    "plt.axvline(x=5, color='red', linestyle='--')               \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e9b1cc-fba1-4663-8475-0ca416cd1c0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Войтинг и стэкинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b608fa01-6e93-4688-b3d9-5684d09c007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Забиваем свои модели и делаем\n",
    "v_reg1 = GradientBoostingRegressor()\n",
    "v_reg2 = RandomForestRegressor()\n",
    "v_reg3 = LinearRegression()\n",
    "\n",
    "\n",
    "\n",
    "# v_reg1.fit(X_train, y_train)\n",
    "# v_reg2.fit(X_train, y_train)\n",
    "# v_reg3.fit(X_train, y_train)\n",
    "\n",
    "ve_reg = VotingRegressor([(\"gb\", v_reg1), (\"rf\", v_reg2), (\"lr\", v_reg3)])\n",
    "ve_reg.fit(X_train, y_train)\n",
    "display(ve_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2a639-05b2-4c74-9aff-4537c84e7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xt = Xd[:20]\n",
    "# v_pred1 = v_reg1.predict(xt)\n",
    "# v_pred2 = v_reg2.predict(xt)\n",
    "# v_pred3 = v_reg3.predict(xt)\n",
    "# v_pred4 = ve_reg.predict(xt)\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.plot(v_pred1, \"gd\", label=\"GradientBoostingRegressor\")\n",
    "# plt.plot(v_pred2, \"b^\", label=\"RandomForestRegressor\")\n",
    "# plt.plot(v_pred3, \"ys\", label=\"LinearRegression\")\n",
    "# plt.plot(v_pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n",
    "# plt.plot(yd[:20], \"ko\", label=\"y_true\")\n",
    "\n",
    "# plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "# plt.ylabel(\"predicted\")\n",
    "# plt.xlabel(\"training samples\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.title(\"Regressor predictions and their average\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf289a47-76e5-4dc9-a276-7756f02a1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стэкинг, если надо, пишем свою модель в final_estimator\n",
    "se_reg = StackingRegressor(\n",
    "    estimators = [(\"gb\", v_reg1), (\"rf\", v_reg2), (\"lr\", v_reg3)],\n",
    "    # final_estimator = ()\n",
    ")\n",
    "se_reg.fit(X_train, y_train)\n",
    "display(se_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e619d965-7d72-4622-b0cd-121994995a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.plot(v_pred1, \"gd\", label=\"GradientBoostingRegressor\")\n",
    "# plt.plot(v_pred2, \"b^\", label=\"RandomForestRegressor\")\n",
    "# plt.plot(v_pred3, \"ys\", label=\"LinearRegression\")\n",
    "# plt.plot(v_pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n",
    "# plt.plot(v_pred5, \"g*\", ms=10, label=\"StackingRegressor\")\n",
    "# plt.plot(yd[:20], \"ko\", label=\"y_true\")\n",
    "\n",
    "# plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "# plt.ylabel(\"predicted\")\n",
    "# plt.xlabel(\"training samples\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.title(\"Regressor predictions and their average\")\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
